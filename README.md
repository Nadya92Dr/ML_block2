# Эксперименты по сравнению моделей

В данном проекте проведены эксперименты по обучению двух моделей: логистической регрессии и дерева решений. Для обеспечения воспроизводимости во всех экспериментах используется фиксированный `random_state=42`.

## Конфигурация моделей
- **Логистическая регрессия:**
  - `max_iter`: число итераций (200).
  - `penalty`: тип регуляризации (l2).
- **Дерево решений:**
  - `max_depth`: максимальная глубина дерева (10).
  - `criterion`: критерий разделения (gini или entropy).

## Эксперименты с использованием MLflow
Все эксперименты логируются с помощью MLflow. Для каждого запуска фиксируются:
- Гиперпараметры
- Метрики: Accuracy, F1 Score, AUC-ROC
- Артефакты: матрица ошибок

## Сравнительная таблица результатов
Точность	F1 Score	AUC-ROC	   Основные гиперпараметры	
Логистическая регрессия	
   0.97	    0.97	     1	           max_iter=200, penalty=l2, random_state=42	
	0.97	0.97	   0.99	           max_iter=100, penalty=l2, random_state=42	
	0.97	0.97	     1	           max_iter=300, penalty=l2, random_state=42	
Дерево решений	
   0.94	    0.94	   0.95        	max_depth=10, criterion=gini, random_state=42	
	0.94	0.94	    0.95	    max_depth=5, criterion=gini, random_state=42	
	0.91	0.90	    0.93	    max_depth=5, criterion=entropy, random_state=42	
	0.94	0.94	    0.95	    max_depth=15, criterion=gini, random_state=42	
	0.94	0.94	    0.95	    max_depth=10, criterion=entropy, random_state=42	
	0.91	0.90	    0.93	    max_depth=15, criterion=entropy, random_state=42	


## Выводы
На основе проведённых экспериментов модель логистической регрессии показала лучшие результаты по метрике AUC-ROC, что говорит о её качестве. Однако, если важна интерпретируемость модели, дерево решений остаётся хорошим выбором для визуализации и понимания процесса принятия решений.

## Запуск экспериментов
Для воспроизводимости экспериментов запустите:
```bash
python run_experiments.py
